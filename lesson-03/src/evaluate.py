import tensorflow as tf
import numpy as np
from sklearn.metrics import classification_report, f1_score, accuracy_score
from tensorflow.keras.utils import Sequence # ƒê·ªÉ m√¥ ph·ªèng DataLoader PyTorch
from tqdm.auto import tqdm
import time

def evaluate_tf(
    model: tf.keras.Model,
    test_data, # S·ª≠ d·ª•ng tf.data.Dataset, tf.keras.utils.Sequence, ho·∫∑c generator
    n_labels: int,
    label_names: list = None # List t√™n c√°c nh√£n
):
    """
    H√†m ƒë√°nh gi√° model tr√™n t·∫≠p test b·∫±ng TensorFlow/Keras.

    Args:
        model (tf.keras.Model): Model ƒë√£ hu·∫•n luy·ªán (Keras).
        test_data: D·ªØ li·ªáu test (v√≠ d·ª•: tf.data.Dataset ho·∫∑c Keras Sequence).
        n_labels (int): S·ªë l∆∞·ª£ng l·ªõp (class) c·ªßa b√†i to√°n.
        label_names (list, optional): T√™n c·ªßa c√°c l·ªõp ƒë·ªÉ in b√°o c√°o chi ti·∫øt.
    """

    print("--- B·∫Øt ƒë·∫ßu ƒë√°nh gi√° tr√™n t·∫≠p Test ---")

    all_preds = []
    all_labels = []

    start_time = time.time()

    # S·ª≠ d·ª•ng model.predict() ƒë·ªÉ l·∫•y t·∫•t c·∫£ d·ª± ƒëo√°n (ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£ h∆°n)
    # ho·∫∑c v√≤ng l·∫∑p th·ªß c√¥ng n·∫øu test_data l√† generator/Sequence ph·ª©c t·∫°p
    
    # C√°ch 1: S·ª≠ d·ª•ng model.predict() (N·∫øu test_data l√† numpy array ho·∫∑c tf.data.Dataset)
    try:
        y_true = []
        # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu v·ªÅ numpy/list ƒë·ªÉ predict
        if isinstance(test_data, tf.data.Dataset):
            # C·∫ßn l·∫•y nh√£n th·∫≠t t·ª´ Dataset n·∫øu predict kh√¥ng tr·∫£ v·ªÅ
            # Gi·∫£ ƒë·ªãnh dataset tr·∫£ v·ªÅ (inputs, labels)
            for inputs, labels in test_data:
                y_true.extend(labels.numpy())
            
            # Predict tr·∫£ v·ªÅ logits/softmax
            y_pred_probs = model.predict(test_data, verbose=0)
            y_true = np.array(y_true)
            
        elif isinstance(test_data, Sequence):
            y_true = np.concatenate([test_data[i][1] for i in range(len(test_data))])
            y_pred_probs = model.predict(test_data, verbose=0)
        
        else:
            # N·∫øu test_data l√† numpy array (ch·ªâ inputs)
            print("L∆∞u √Ω: Kh√¥ng t√¨m th·∫•y nh√£n th·∫≠t. C·∫ßn data set ho·∫∑c generator c√≥ nh√£n.")
            return
            
    except Exception as e:
        # C√°ch 2: L·∫∑p th·ªß c√¥ng (ƒë·ªÉ x·ª≠ l√Ω c√°c lo·∫°i d·ªØ li·ªáu ph·ª©c t·∫°p h∆°n)
        print(f"L·ªói khi d√πng model.predict(): {e}. Chuy·ªÉn sang l·∫∑p th·ªß c√¥ng.")
        
        y_true = []
        y_pred_probs = []
        for batch in tqdm(test_data, desc="Evaluating"):
            inputs, labels = batch # Gi·∫£ s·ª≠ data tr·∫£ v·ªÅ (inputs, labels)
            
            # Forward pass
            outputs = model.predict_on_batch(inputs)
            
            # L∆∞u l·∫°i
            y_pred_probs.extend(outputs)
            y_true.extend(labels.numpy())
            
        y_true = np.array(y_true)
        y_pred_probs = np.array(y_pred_probs)


    # L·∫•y d·ª± ƒëo√°n cu·ªëi c√πng (ch·ªâ s·ªë c·ªßa l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t)
    # y_pred_probs c√≥ shape (n_samples, n_labels)
    all_preds = np.argmax(y_pred_probs, axis=1)
    # y_true l√† nh√£n th·∫≠t (n_samples,)
    all_labels = y_true

    end_time = time.time()
    
    # --- T√≠nh to√°n c√°c ch·ªâ s·ªë cu·ªëi c√πng ---
    # Keras Loss: ƒê·ªÉ t√≠nh Test Loss, c·∫ßn d√πng model.evaluate() ri√™ng.
    # Trong h√†m n√†y, ta t·∫≠p trung v√†o c√°c metrics.
    
    # T√≠nh F1-Score (Macro) v√† Accuracy d√πng Sklearn (nh∆∞ PyTorch ƒë√£ d√πng torchmetrics)
    test_f1 = f1_score(all_labels, all_preds, average="macro")
    test_acc = accuracy_score(all_labels, all_preds)

    print("\n--- üèÅ K·∫øt qu·∫£ ƒê√°nh gi√° tr√™n t·∫≠p Test ---")
    print(f"Th·ªùi gian ƒë√°nh gi√°: {end_time - start_time:.2f} gi√¢y")
    # Loss: Kh√¥ng t√≠nh tr·ª±c ti·∫øp trong predict loop, n√™n b·ªè qua ho·∫∑c d√πng model.evaluate()
    # print(f"Test Loss: \t(T√≠nh b·∫±ng model.evaluate() ri√™ng bi·ªát)")
    print(f"Test Accuracy: \t{test_acc * 100:.2f}%")
    print(f"Test F1-Score (Macro): \t{test_f1:.4f}")
    
    # --- In b√°o c√°o chi ti·∫øt c·ªßa Sklearn ---
    print("\nüìä B√°o c√°o chi ti·∫øt (Classification Report):")
    
    if label_names and len(label_names) == n_labels:
        report = classification_report(all_labels, all_preds, target_names=label_names)
    else:
        if label_names and len(label_names) != n_labels:
            print(f"(L∆∞u √Ω: S·ªë l∆∞·ª£ng label_names kh√¥ng kh·ªõp n_labels. S·∫Ω d√πng ch·ªâ s·ªë 0, 1, 2...)")
        report = classification_report(all_labels, all_preds)
        
    print(report)
    
    # Tr·∫£ v·ªÅ m·ªôt dict ch·ª©a c√°c k·∫øt qu·∫£
    return {
        "test_accuracy": test_acc,
        "test_f1_macro": test_f1,
        "classification_report": report
    }
