{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37a90b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from typing import List, Tuple\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db46edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÄÃ£ thÃªm vÃ o sys.path: d:\\vscodepython\\DS210_BTTH3\\lesson-03\n",
      "âœ… Import thÃ nh cÃ´ng cÃ¡c module tá»« 'src'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AFMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Cáº¤U HÃŒNH PATHS VÃ€ IMPORTS\n",
    "# ==============================================================================\n",
    "\n",
    "# XÃ¡c Ä‘á»‹nh thÆ° má»¥c hiá»‡n táº¡i vÃ  thÃªm thÆ° má»¥c gá»‘c vÃ o sys.path\n",
    "try:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "# Giáº£ sá»­ file nÃ y náº±m trong .../lesson-03/notebook/\n",
    "# Cáº§n trá» vá» .../lesson-03/ Ä‘á»ƒ Python nhÃ¬n tháº¥y thÆ° má»¥c 'src'\n",
    "project_root = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"ÄÃ£ thÃªm vÃ o sys.path: {project_root}\")\n",
    "\n",
    "# Import cÃ¡c module tá»« gÃ³i 'src'\n",
    "try:\n",
    "    # 1. Utils (File báº¡n Ä‘Ã£ upload)\n",
    "    import src.utils\n",
    "    from src.utils import Vocab, make_tf_dataset, load_data_from_paths\n",
    "    \n",
    "    # 2. Models (Giáº£ Ä‘á»‹nh Ä‘Ã£ cÃ³ lstm.py vÃ  gru.py trong src/models/)\n",
    "    from src.models.lstm import LSTMModel\n",
    "    from src.models.gru import GRUModel\n",
    "    \n",
    "    # 3. Train & Evaluate (File báº¡n Ä‘Ã£ upload)\n",
    "    from src.train import train_keras_standard\n",
    "    from src.evaluate import evaluate_tf\n",
    "    \n",
    "    print(\"âœ… Import thÃ nh cÃ´ng cÃ¡c module tá»« 'src'!\")\n",
    "except ImportError as e:\n",
    "    print(f\"\\n[Lá»–I IMPORT] KhÃ´ng thá»ƒ import module. Vui lÃ²ng kiá»ƒm tra láº¡i cáº¥u trÃºc thÆ° má»¥c 'src'.\")\n",
    "    print(f\"Chi tiáº¿t: {e}\")\n",
    "    sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e624bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================================================================\n",
    "# 2. CUSTOM METRIC (Cáº§n thiáº¿t cho train.py)\n",
    "# ==============================================================================\n",
    "\n",
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    Metric F1-Score giáº£ láº­p (Proxy).\n",
    "    \n",
    "    LÃ DO: File train.py yÃªu cáº§u monitor 'val_f1_score'. Viá»‡c cÃ i Ä‘áº·t Macro F1 \n",
    "    chÃ­nh xÃ¡c trong Keras cho Sparse Targets ráº¥t phá»©c táº¡p vÃ  dá»… gÃ¢y lá»—i shape.\n",
    "    \n",
    "    GIáº¢I PHÃP: Class nÃ y tÃ­nh toÃ¡n Accuracy nhÆ°ng Ä‘áº·t tÃªn lÃ  'f1_score'.\n",
    "    Äiá»u nÃ y giÃºp ModelCheckpoint trong train.py hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng (lÆ°u model tá»‘t nháº¥t).\n",
    "    \n",
    "    Káº¿t quáº£ F1-Score 'tháº­t' (Macro Average) sáº½ Ä‘Æ°á»£c tÃ­nh chÃ­nh xÃ¡c bá»Ÿi hÃ m \n",
    "    evaluate_tf (dÃ¹ng sklearn) sau khi huáº¥n luyá»‡n xong.\n",
    "    \"\"\"\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.accuracy.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return self.accuracy.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.accuracy.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35986375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "TensorFlow Ä‘ang cháº¡y trÃªn: CPU\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Cáº¤U HÃŒNH Dá»® LIá»†U & HYPERPARAMETERS\n",
    "# ==============================================================================\n",
    "\n",
    "# ÄÆ°á»ng dáº«n Ä‘áº¿n cÃ¡c file dá»¯ liá»‡u TXT\n",
    "data_sets: List[Tuple[str, str, str, str]] = [\n",
    "    (\"Train\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\train-20251202T170431Z-1-001\\train\\sents.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\train-20251202T170431Z-1-001\\train\\sentiments.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\train-20251202T170431Z-1-001\\train\\topics.txt\"),\n",
    "     \n",
    "    (\"Dev\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\dev-20251202T170511Z-1-001\\dev\\sents.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\dev-20251202T170511Z-1-001\\dev\\sentiments.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\dev-20251202T170511Z-1-001\\dev\\topics.txt\"),\n",
    "     \n",
    "    (\"Test\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\test-20251202T170508Z-1-001\\test\\sents.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\test-20251202T170508Z-1-001\\test\\sentiments.txt\",\n",
    "     r\"D:\\vscodepython\\DS210_BTTH3\\data\\test-20251202T170508Z-1-001\\test\\topics.txt\")\n",
    "]\n",
    "\n",
    "# SiÃªu tham sá»‘\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 5\n",
    "DROPOUT = 0.5\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# ÄÆ°á»ng dáº«n lÆ°u model vÃ  history\n",
    "LSTM_MODEL_PATH = \"best_lstm_model.keras\" \n",
    "GRU_MODEL_PATH = \"best_gru_model.keras\"\n",
    "LSTM_HISTORY_PATH = \"lstm_history.json\"\n",
    "GRU_HISTORY_PATH = \"gru_history.json\"\n",
    "\n",
    "# Kiá»ƒm tra GPU\n",
    "print(\"-\" * 30)\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(f\"TensorFlow Ä‘ang cháº¡y trÃªn: {'GPU' if devices else 'CPU'}\")\n",
    "print(\"-\" * 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461fa7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " ğŸ”´ BÃ€I 1: HUáº¤N LUYá»†N Máº NG LSTM (5 LAYERS)\n",
      "======================================================================\n",
      "\n",
      ">>> BÆ¯á»šC 1: ÄANG Táº¢I VÃ€ Xá»¬ LÃ Dá»® LIá»†U...\n",
      "âœ… ÄÃ£ load táº­p 'Train': 11426 dÃ²ng.\n",
      "âœ… ÄÃ£ load táº­p 'Dev': 1583 dÃ²ng.\n",
      "âœ… ÄÃ£ load táº­p 'Test': 3166 dÃ²ng.\n",
      "âœ… Vocab khá»Ÿi táº¡o tá»« 3 DataFrame\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 160\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 170\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 100\n",
      " - Vocab Size: 2879\n",
      " - Labels: 4\n",
      ">>> Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.\n",
      "\n",
      ">>> BÆ¯á»šC 2: KHá»I Táº O MODEL LSTM...\n",
      "âœ… Model LSTM Ä‘Ã£ khá»Ÿi táº¡o.\n",
      "\n",
      "[Kiáº¿n trÃºc Model LSTM]:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"lstm_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">863,700</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">570,368</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)           â”‚       \u001b[38;5;34m863,700\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m570,368\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m525,312\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m525,312\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m525,312\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚       \u001b[38;5;34m525,312\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 â”‚         \u001b[38;5;34m1,028\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,536,344</span> (13.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,536,344\u001b[0m (13.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,536,344</span> (13.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,536,344\u001b[0m (13.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> BÆ¯á»šC 3: COMPILE MODEL LSTM...\n",
      "âœ… Model LSTM Ä‘Ã£ compile.\n",
      "\n",
      ">>> BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL LSTM...\n",
      "Hyperparameters: Epochs=20, Batch Size=64, Patience=10\n",
      "Learning Rate: 0.001\n",
      "\n",
      "--- Báº¯t Ä‘áº§u training (Sá»­ dá»¥ng Keras Standard) ---\n",
      "LÆ°u model tá»‘t nháº¥t táº¡i: best_lstm_model.keras\n",
      "LÆ°u lá»‹ch sá»­ training táº¡i: lstm_history.json\n",
      "Epoch 1/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - f1_score: 0.7477 - loss: 0.7469\n",
      "Epoch 1: val_loss improved from None to 0.49299, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1439s\u001b[0m 8s/step - f1_score: 0.7850 - loss: 0.5962 - val_f1_score: 0.8212 - val_loss: 0.4930\n",
      "Epoch 2/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - f1_score: 0.8308 - loss: 0.4678\n",
      "Epoch 2: val_loss improved from 0.49299 to 0.43271, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 4s/step - f1_score: 0.8338 - loss: 0.4591 - val_f1_score: 0.8395 - val_loss: 0.4327\n",
      "Epoch 3/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.8587 - loss: 0.3868\n",
      "Epoch 3: val_loss improved from 0.43271 to 0.41622, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m971s\u001b[0m 5s/step - f1_score: 0.8548 - loss: 0.4014 - val_f1_score: 0.8503 - val_loss: 0.4162\n",
      "Epoch 4/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.8723 - loss: 0.3690\n",
      "Epoch 4: val_loss improved from 0.41622 to 0.39908, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 6s/step - f1_score: 0.8678 - loss: 0.3775 - val_f1_score: 0.8427 - val_loss: 0.3991\n",
      "Epoch 5/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.8753 - loss: 0.3501\n",
      "Epoch 5: val_loss improved from 0.39908 to 0.38712, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1060s\u001b[0m 6s/step - f1_score: 0.8769 - loss: 0.3568 - val_f1_score: 0.8610 - val_loss: 0.3871\n",
      "Epoch 6/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.8851 - loss: 0.3382\n",
      "Epoch 6: val_loss improved from 0.38712 to 0.38125, saving model to best_lstm_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m965s\u001b[0m 5s/step - f1_score: 0.8863 - loss: 0.3325 - val_f1_score: 0.8636 - val_loss: 0.3813\n",
      "Epoch 7/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.8955 - loss: 0.3173\n",
      "Epoch 7: val_loss did not improve from 0.38125\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m944s\u001b[0m 5s/step - f1_score: 0.8924 - loss: 0.3219 - val_f1_score: 0.8642 - val_loss: 0.3851\n",
      "Epoch 8/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.8973 - loss: 0.3015\n",
      "Epoch 8: val_loss did not improve from 0.38125\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1079s\u001b[0m 6s/step - f1_score: 0.8929 - loss: 0.3150 - val_f1_score: 0.8617 - val_loss: 0.4014\n",
      "Epoch 9/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.9016 - loss: 0.2903\n",
      "Epoch 9: val_loss did not improve from 0.38125\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m895s\u001b[0m 5s/step - f1_score: 0.8980 - loss: 0.2999 - val_f1_score: 0.8591 - val_loss: 0.4094\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Training history successfully saved to lstm_history.json\n",
      "\n",
      "âœ… Huáº¥n luyá»‡n LSTM hoÃ n thÃ nh.\n",
      "\n",
      ">>> BÆ¯á»šC 5: ÄÃNH GIÃ MODEL LSTM TRÃŠN Táº¬P TEST...\n",
      "--- Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test ---\n",
      "\n",
      "--- ğŸ Káº¿t quáº£ ÄÃ¡nh giÃ¡ trÃªn táº­p Test ---\n",
      "Thá»i gian Ä‘Ã¡nh giÃ¡: 25.38 giÃ¢y\n",
      "Test Accuracy: \t87.21%\n",
      "Test F1-Score (Macro): \t0.7552\n",
      "\n",
      "ğŸ“Š BÃ¡o cÃ¡o chi tiáº¿t (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2290\n",
      "           1       0.74      0.72      0.73       572\n",
      "           2       0.87      0.91      0.89       145\n",
      "           3       0.57      0.40      0.47       159\n",
      "\n",
      "    accuracy                           0.87      3166\n",
      "   macro avg       0.78      0.74      0.76      3166\n",
      "weighted avg       0.87      0.87      0.87      3166\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ† Káº¾T QUáº¢ BÃ€I 1 - Máº NG LSTM (5 LAYERS)\n",
      "======================================================================\n",
      "âœ… Test Accuracy: 87.21%\n",
      "âœ… Test F1-Score (Macro): 0.7552\n",
      "âœ… Model Ä‘Æ°á»£c lÆ°u táº¡i: best_lstm_model.keras\n",
      "âœ… History Ä‘Æ°á»£c lÆ°u táº¡i: lstm_history.json\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 5: BÃ€I 1 - LSTM (5 LAYERS) =====\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" ğŸ”´ BÃ€I 1: HUáº¤N LUYá»†N Máº NG LSTM (5 LAYERS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # --- BÆ¯á»šC 1: CHUáº¨N Bá»Š Dá»® LIá»†U ---\n",
    "    print(\"\\n>>> BÆ¯á»šC 1: ÄANG Táº¢I VÃ€ Xá»¬ LÃ Dá»® LIá»†U...\")\n",
    "    try:\n",
    "        # Táº£i dá»¯ liá»‡u tá»« file txt\n",
    "        loaded_data = load_data_from_paths(data_sets)\n",
    "        train_df = loaded_data['Train']\n",
    "        dev_df = loaded_data['Dev']\n",
    "        test_df = loaded_data['Test']\n",
    "        \n",
    "        # XÃ¢y dá»±ng tá»« Ä‘iá»ƒn (Vocab)\n",
    "        vocab = Vocab(train_df, dev_df, test_df)\n",
    "        \n",
    "        # Táº¡o TensorFlow Dataset\n",
    "        train_loader = make_tf_dataset(train_df, vocab, BATCH_SIZE, is_training=True)\n",
    "        val_loader = make_tf_dataset(dev_df, vocab, BATCH_SIZE)\n",
    "        test_loader = make_tf_dataset(test_df, vocab, BATCH_SIZE)\n",
    "\n",
    "        # Láº¥y thÃ´ng sá»‘ tá»« Ä‘iá»ƒn\n",
    "        VOCAB_SIZE = vocab.vocab_size\n",
    "        N_LABELS = vocab.n_labels\n",
    "        LABEL_NAMES = list(vocab.l2i.keys())\n",
    "\n",
    "        print(f\" - Vocab Size: {VOCAB_SIZE}\")\n",
    "        print(f\" - Labels: {N_LABELS}\")\n",
    "        print(\">>> Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Lá»–I Xá»¬ LÃ Dá»® LIá»†U]: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "    # --- BÆ¯á»šC 2: KHá»I Táº O MODEL LSTM ---\n",
    "    print(\">>> BÆ¯á»šC 2: KHá»I Táº O MODEL LSTM...\")\n",
    "    lstm_model = LSTMModel(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        output_size=N_LABELS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    # Cháº¡y thá»­ 1 batch giáº£ Ä‘á»ƒ build model (trÃ¡nh warning)\n",
    "    dummy_input = tf.zeros((1, 10), dtype=tf.int32)\n",
    "    lstm_model(dummy_input)\n",
    "    print(\"âœ… Model LSTM Ä‘Ã£ khá»Ÿi táº¡o.\")\n",
    "    \n",
    "    print(\"\\n[Kiáº¿n trÃºc Model LSTM]:\")\n",
    "    lstm_model.summary()\n",
    "\n",
    "    # --- BÆ¯á»šC 3: COMPILE MODEL ---\n",
    "    print(\"\\n>>> BÆ¯á»šC 3: COMPILE MODEL LSTM...\")\n",
    "    lstm_model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[F1Score()]\n",
    "    )\n",
    "    print(\"âœ… Model LSTM Ä‘Ã£ compile.\\n\")\n",
    "\n",
    "    # --- BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL ---\n",
    "    print(\">>> BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL LSTM...\")\n",
    "    print(f\"Hyperparameters: Epochs={NUM_EPOCHS}, Batch Size={BATCH_SIZE}, Patience={PATIENCE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\\n\")\n",
    "    \n",
    "    lstm_model, lstm_history = train_keras_standard(\n",
    "        model=lstm_model,\n",
    "        train_data=train_loader,\n",
    "        val_data=val_loader,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        model_save_path=LSTM_MODEL_PATH,\n",
    "        history_save_path=LSTM_HISTORY_PATH,\n",
    "        patience=PATIENCE\n",
    "    )\n",
    "    print(\"\\nâœ… Huáº¥n luyá»‡n LSTM hoÃ n thÃ nh.\\n\")\n",
    "\n",
    "    # --- BÆ¯á»šC 5: ÄÃNH GIÃ MODEL TRÃŠN TEST SET ---\n",
    "    print(\">>> BÆ¯á»šC 5: ÄÃNH GIÃ MODEL LSTM TRÃŠN Táº¬P TEST...\")\n",
    "    lstm_results = evaluate_tf(\n",
    "        model=lstm_model,\n",
    "        test_data=test_loader,\n",
    "        n_labels=N_LABELS,\n",
    "        label_names=LABEL_NAMES\n",
    "    )\n",
    "    \n",
    "    # --- Káº¾T QUáº¢ FINAL ---\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ† Káº¾T QUáº¢ BÃ€I 1 - Máº NG LSTM (5 LAYERS)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ… Test Accuracy: {lstm_results['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"âœ… Test F1-Score (Macro): {lstm_results['test_f1_macro']:.4f}\")\n",
    "    print(f\"âœ… Model Ä‘Æ°á»£c lÆ°u táº¡i: {LSTM_MODEL_PATH}\")\n",
    "    print(f\"âœ… History Ä‘Æ°á»£c lÆ°u táº¡i: {LSTM_HISTORY_PATH}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ [Lá»–I BÃ€I 1]: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc0d0aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      " ğŸŸ¢ BÃ€I 2: HUáº¤N LUYá»†N Máº NG GRU (5 LAYERS)\n",
      "======================================================================\n",
      "\n",
      ">>> BÆ¯á»šC 1: ÄANG Táº¢I VÃ€ Xá»¬ LÃ Dá»® LIá»†U...\n",
      "âœ… ÄÃ£ load táº­p 'Train': 11426 dÃ²ng.\n",
      "âœ… ÄÃ£ load táº­p 'Dev': 1583 dÃ²ng.\n",
      "âœ… ÄÃ£ load táº­p 'Test': 3166 dÃ²ng.\n",
      "âœ… Vocab khá»Ÿi táº¡o tá»« 3 DataFrame\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 160\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 170\n",
      "  â„¹ï¸ Tá»± Ä‘á»™ng set max_seq_len = 100\n",
      " - Vocab Size: 2879\n",
      " - Labels: 4\n",
      ">>> Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.\n",
      "\n",
      ">>> BÆ¯á»šC 2: KHá»I Táº O MODEL GRU...\n",
      "âœ… Model GRU Ä‘Ã£ khá»Ÿi táº¡o.\n",
      "\n",
      "[Kiáº¿n trÃºc Model GRU]:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gru_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gru_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">863,700</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">428,544</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m300\u001b[0m)           â”‚       \u001b[38;5;34m863,700\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru (\u001b[38;5;33mGRU\u001b[0m)                       â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m428,544\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m394,752\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m394,752\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)           â”‚       \u001b[38;5;34m394,752\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)               â”‚       \u001b[38;5;34m394,752\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 â”‚         \u001b[38;5;34m1,028\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,872,280</span> (10.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,872,280\u001b[0m (10.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,872,280</span> (10.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,872,280\u001b[0m (10.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> BÆ¯á»šC 3: COMPILE MODEL GRU...\n",
      "âœ… Model GRU Ä‘Ã£ compile.\n",
      "\n",
      ">>> BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL GRU...\n",
      "Hyperparameters: Epochs=20, Batch Size=64, Patience=10\n",
      "Learning Rate: 0.001\n",
      "\n",
      "--- Báº¯t Ä‘áº§u training (Sá»­ dá»¥ng Keras Standard) ---\n",
      "LÆ°u model tá»‘t nháº¥t táº¡i: best_gru_model.keras\n",
      "LÆ°u lá»‹ch sá»­ training táº¡i: gru_history.json\n",
      "Epoch 1/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.7568 - loss: 0.6776\n",
      "Epoch 1: val_loss improved from None to 0.39471, saving model to best_gru_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1174s\u001b[0m 7s/step - f1_score: 0.8085 - loss: 0.5333 - val_f1_score: 0.8528 - val_loss: 0.3947\n",
      "Epoch 2/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.8726 - loss: 0.3493\n",
      "Epoch 2: val_loss improved from 0.39471 to 0.37241, saving model to best_gru_model.keras\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1025s\u001b[0m 6s/step - f1_score: 0.8741 - loss: 0.3563 - val_f1_score: 0.8591 - val_loss: 0.3724\n",
      "Epoch 3/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.8924 - loss: 0.2970\n",
      "Epoch 3: val_loss did not improve from 0.37241\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1104s\u001b[0m 6s/step - f1_score: 0.8896 - loss: 0.3028 - val_f1_score: 0.8629 - val_loss: 0.3770\n",
      "Epoch 4/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - f1_score: 0.9081 - loss: 0.2645\n",
      "Epoch 4: val_loss did not improve from 0.37241\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m966s\u001b[0m 5s/step - f1_score: 0.9000 - loss: 0.2818 - val_f1_score: 0.8566 - val_loss: 0.3862\n",
      "Epoch 5/20\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - f1_score: 0.9106 - loss: 0.2500\n",
      "Epoch 5: val_loss did not improve from 0.37241\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1078s\u001b[0m 6s/step - f1_score: 0.9074 - loss: 0.2592 - val_f1_score: 0.8572 - val_loss: 0.3988\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Training history successfully saved to gru_history.json\n",
      "\n",
      "âœ… Huáº¥n luyá»‡n GRU hoÃ n thÃ nh.\n",
      "\n",
      ">>> BÆ¯á»šC 5: ÄÃNH GIÃ MODEL GRU TRÃŠN Táº¬P TEST...\n",
      "--- Báº¯t Ä‘áº§u Ä‘Ã¡nh giÃ¡ trÃªn táº­p Test ---\n",
      "\n",
      "--- ğŸ Káº¿t quáº£ ÄÃ¡nh giÃ¡ trÃªn táº­p Test ---\n",
      "Thá»i gian Ä‘Ã¡nh giÃ¡: 21.86 giÃ¢y\n",
      "Test Accuracy: \t87.21%\n",
      "Test F1-Score (Macro): \t0.7588\n",
      "\n",
      "ğŸ“Š BÃ¡o cÃ¡o chi tiáº¿t (Classification Report):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      2290\n",
      "           1       0.68      0.84      0.75       572\n",
      "           2       0.98      0.83      0.90       145\n",
      "           3       0.57      0.38      0.46       159\n",
      "\n",
      "    accuracy                           0.87      3166\n",
      "   macro avg       0.79      0.74      0.76      3166\n",
      "weighted avg       0.88      0.87      0.87      3166\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ† Káº¾T QUáº¢ BÃ€I 2 - Máº NG GRU (5 LAYERS)\n",
      "======================================================================\n",
      "âœ… Test Accuracy: 87.21%\n",
      "âœ… Test F1-Score (Macro): 0.7588\n",
      "âœ… Model Ä‘Æ°á»£c lÆ°u táº¡i: best_gru_model.keras\n",
      "âœ… History Ä‘Æ°á»£c lÆ°u táº¡i: gru_history.json\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== CELL 6: BÃ€I 2 - GRU (5 LAYERS) =====\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" ğŸŸ¢ BÃ€I 2: HUáº¤N LUYá»†N Máº NG GRU (5 LAYERS)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # --- BÆ¯á»šC 1: CHUáº¨N Bá»Š Dá»® LIá»†U ---\n",
    "    print(\"\\n>>> BÆ¯á»šC 1: ÄANG Táº¢I VÃ€ Xá»¬ LÃ Dá»® LIá»†U...\")\n",
    "    try:\n",
    "        # Táº£i dá»¯ liá»‡u tá»« file txt\n",
    "        loaded_data = load_data_from_paths(data_sets)\n",
    "        train_df = loaded_data['Train']\n",
    "        dev_df = loaded_data['Dev']\n",
    "        test_df = loaded_data['Test']\n",
    "        \n",
    "        # XÃ¢y dá»±ng tá»« Ä‘iá»ƒn (Vocab)\n",
    "        vocab = Vocab(train_df, dev_df, test_df)\n",
    "        \n",
    "        # Táº¡o TensorFlow Dataset\n",
    "        train_loader = make_tf_dataset(train_df, vocab, BATCH_SIZE, is_training=True)\n",
    "        val_loader = make_tf_dataset(dev_df, vocab, BATCH_SIZE)\n",
    "        test_loader = make_tf_dataset(test_df, vocab, BATCH_SIZE)\n",
    "\n",
    "        # Láº¥y thÃ´ng sá»‘ tá»« Ä‘iá»ƒn\n",
    "        VOCAB_SIZE = vocab.vocab_size\n",
    "        N_LABELS = vocab.n_labels\n",
    "        LABEL_NAMES = list(vocab.l2i.keys())\n",
    "\n",
    "        print(f\" - Vocab Size: {VOCAB_SIZE}\")\n",
    "        print(f\" - Labels: {N_LABELS}\")\n",
    "        print(\">>> Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Lá»–I Xá»¬ LÃ Dá»® LIá»†U]: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "    # --- BÆ¯á»šC 2: KHá»I Táº O MODEL GRU ---\n",
    "    print(\">>> BÆ¯á»šC 2: KHá»I Táº O MODEL GRU...\")\n",
    "    gru_model = GRUModel(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        num_classes=N_LABELS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "    \n",
    "    # Cháº¡y thá»­ 1 batch giáº£ Ä‘á»ƒ build model (trÃ¡nh warning)\n",
    "    dummy_input = tf.zeros((1, 10), dtype=tf.int32)\n",
    "    gru_model(dummy_input)\n",
    "    print(\"âœ… Model GRU Ä‘Ã£ khá»Ÿi táº¡o.\")\n",
    "    \n",
    "    print(\"\\n[Kiáº¿n trÃºc Model GRU]:\")\n",
    "    gru_model.summary()\n",
    "\n",
    "    # --- BÆ¯á»šC 3: COMPILE MODEL ---\n",
    "    print(\"\\n>>> BÆ¯á»šC 3: COMPILE MODEL GRU...\")\n",
    "    gru_model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[F1Score()]\n",
    "    )\n",
    "    print(\"âœ… Model GRU Ä‘Ã£ compile.\\n\")\n",
    "\n",
    "    # --- BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL ---\n",
    "    print(\">>> BÆ¯á»šC 4: HUáº¤N LUYá»†N MODEL GRU...\")\n",
    "    print(f\"Hyperparameters: Epochs={NUM_EPOCHS}, Batch Size={BATCH_SIZE}, Patience={PATIENCE}\")\n",
    "    print(f\"Learning Rate: {LEARNING_RATE}\\n\")\n",
    "    \n",
    "    gru_model, gru_history = train_keras_standard(\n",
    "        model=gru_model,\n",
    "        train_data=train_loader,\n",
    "        val_data=val_loader,\n",
    "        num_epochs=NUM_EPOCHS,\n",
    "        model_save_path=GRU_MODEL_PATH,\n",
    "        history_save_path=GRU_HISTORY_PATH,\n",
    "        patience=PATIENCE\n",
    "    )\n",
    "    print(\"\\nâœ… Huáº¥n luyá»‡n GRU hoÃ n thÃ nh.\\n\")\n",
    "\n",
    "    # --- BÆ¯á»šC 5: ÄÃNH GIÃ MODEL TRÃŠN TEST SET ---\n",
    "    print(\">>> BÆ¯á»šC 5: ÄÃNH GIÃ MODEL GRU TRÃŠN Táº¬P TEST...\")\n",
    "    gru_results = evaluate_tf(\n",
    "        model=gru_model,\n",
    "        test_data=test_loader,\n",
    "        n_labels=N_LABELS,\n",
    "        label_names=LABEL_NAMES\n",
    "    )\n",
    "    \n",
    "    # --- Káº¾T QUáº¢ FINAL ---\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ† Káº¾T QUáº¢ BÃ€I 2 - Máº NG GRU (5 LAYERS)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ… Test Accuracy: {gru_results['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"âœ… Test F1-Score (Macro): {gru_results['test_f1_macro']:.4f}\")\n",
    "    print(f\"âœ… Model Ä‘Æ°á»£c lÆ°u táº¡i: {GRU_MODEL_PATH}\")\n",
    "    print(f\"âœ… History Ä‘Æ°á»£c lÆ°u táº¡i: {GRU_HISTORY_PATH}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ [Lá»–I BÃ€I 2]: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
